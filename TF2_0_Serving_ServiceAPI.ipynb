{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2.0_Serving_ServiceAPI",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNL6kxIZGQYUoGzY0aYQGyA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmVu4hzMkBPi"
      },
      "source": [
        "# Import Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FXWnDi0tV8l",
        "outputId": "dbcff089-889f-4253-e1dd-cbdfce175979"
      },
      "source": [
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update\n",
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2943  100  2943    0     0  30656      0 --:--:-- --:--:-- --:--:-- 30656\n",
            "OK\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:11 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [347 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:14 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [340 B]\n",
            "Hit:15 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Ign:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [630 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:18 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,221 kB]\n",
            "Get:20 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [473 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,418 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,188 kB]\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,777 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [506 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,656 kB]\n",
            "Get:27 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [909 kB]\n",
            "Get:28 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.9 kB]\n",
            "Get:29 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [41.5 kB]\n",
            "Fetched 13.2 MB in 5s (2,656 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "83 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 83 not upgraded.\n",
            "Need to get 326 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.5.1 [326 MB]\n",
            "Fetched 326 MB in 4s (81.2 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.5.1_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.5.1) ...\n",
            "Setting up tensorflow-model-server (2.5.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGj3Fhr7j47R"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "import requests\n",
        "import subprocess\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCcG0a1UvssH"
      },
      "source": [
        "MODEL_DIR = tempfile.gettempdir()\n",
        "def gen_export_path(ver):    \n",
        "    export_path = os.path.join(MODEL_DIR, str(ver))\n",
        "    return export_path "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spTa54MTkLSW"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eYEKjqykCZm",
        "outputId": "8d91961d-c330-4b0c-bc51-ee99fdd6b152"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "X_train, X_test = np.expand_dims(X_train, -1), np.expand_dims(X_test, -1) # expand (height x weight) to (height x weight x color), color = 1 for grayscale\n",
        "print(X_train.shape, X_test.shape)\n",
        "\n",
        "K = len(set(y_train))\n",
        "print(K)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28, 1) (10000, 28, 28, 1)\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzAqMqgFxapV"
      },
      "source": [
        "# Label mapping\n",
        "labels = '''T-shirt/top\n",
        "Trouser\n",
        "Pullover\n",
        "Dress\n",
        "Coat\n",
        "Sandal\n",
        "Shirt\n",
        "Sneaker\n",
        "Bag\n",
        "Ankle boot'''.split(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKAMof-Vs86S"
      },
      "source": [
        "## Model - Large"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfzVphIWkcxt",
        "outputId": "2cddccba-7c4d-45de-ee86-ea06d9803fe6"
      },
      "source": [
        "i = Input(shape=X_train[0].shape)\n",
        "x = Conv2D(32, (3, 3), strides=2, activation='relu')(i)\n",
        "x = Conv2D(64, (3, 3), strides=2, activation='relu')(x)\n",
        "x = Conv2D(128, (3, 3), strides=2, activation='relu')(x)\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(K, activation='softmax')(x)\n",
        "\n",
        "model = Model(i, x)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 13, 13, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 6, 6, 64)          18496     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 2, 2, 128)         73856     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 360,458\n",
            "Trainable params: 360,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6Qr4JM2lSPe",
        "outputId": "3932d77c-184a-4abe-9e88-783b19e11ac7"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 38s 3ms/step - loss: 0.5310 - accuracy: 0.8031 - val_loss: 0.4156 - val_accuracy: 0.8473\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3652 - accuracy: 0.8631 - val_loss: 0.3732 - val_accuracy: 0.8578\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3158 - accuracy: 0.8801 - val_loss: 0.3208 - val_accuracy: 0.8835\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2813 - accuracy: 0.8944 - val_loss: 0.3157 - val_accuracy: 0.8837\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2567 - accuracy: 0.9023 - val_loss: 0.3124 - val_accuracy: 0.8884\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2368 - accuracy: 0.9107 - val_loss: 0.3075 - val_accuracy: 0.8892\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2173 - accuracy: 0.9183 - val_loss: 0.3003 - val_accuracy: 0.8968\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2020 - accuracy: 0.9214 - val_loss: 0.3014 - val_accuracy: 0.8962\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1861 - accuracy: 0.9293 - val_loss: 0.3003 - val_accuracy: 0.9024\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1726 - accuracy: 0.9321 - val_loss: 0.3087 - val_accuracy: 0.8942\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1649 - accuracy: 0.9373 - val_loss: 0.3262 - val_accuracy: 0.8978\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1517 - accuracy: 0.9414 - val_loss: 0.3199 - val_accuracy: 0.8992\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1460 - accuracy: 0.9435 - val_loss: 0.3362 - val_accuracy: 0.8965\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1381 - accuracy: 0.9468 - val_loss: 0.3440 - val_accuracy: 0.8975\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1325 - accuracy: 0.9500 - val_loss: 0.3543 - val_accuracy: 0.8958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n1zZveGltiG",
        "outputId": "e16a3ec0-27fa-41a4-d93b-dec651ced73c"
      },
      "source": [
        "export_path = gen_export_path(1)\n",
        "tf.saved_model.save(model, export_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
            "INFO:tensorflow:Assets written to: /tmp/1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjHDjCujzMyl"
      },
      "source": [
        "## Model - Tiny"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBr5eMkvzOgz",
        "outputId": "ed3b88e3-0300-43f4-863c-6a836dd1761a"
      },
      "source": [
        "i = Input(shape=X_train[0].shape)\n",
        "x = Conv2D(32, (3, 3), strides=2, activation='relu')(i)\n",
        "x = Flatten()(x)\n",
        "x = Dense(K, activation='softmax')(x)\n",
        "\n",
        "model2 = Model(i, x)\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 32)        320       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                54090     \n",
            "=================================================================\n",
            "Total params: 54,410\n",
            "Trainable params: 54,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atI3yPEkzQuW",
        "outputId": "7a03096b-83f6-4d40-98c0-e137c2910e4b"
      },
      "source": [
        "model2.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "r2 = model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4646 - accuracy: 0.8370 - val_loss: 0.3757 - val_accuracy: 0.8670\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3285 - accuracy: 0.8848 - val_loss: 0.3405 - val_accuracy: 0.8787\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2950 - accuracy: 0.8947 - val_loss: 0.3169 - val_accuracy: 0.8849\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2730 - accuracy: 0.9020 - val_loss: 0.3124 - val_accuracy: 0.8866\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2569 - accuracy: 0.9082 - val_loss: 0.3066 - val_accuracy: 0.8886\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2436 - accuracy: 0.9126 - val_loss: 0.2995 - val_accuracy: 0.8937\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2307 - accuracy: 0.9165 - val_loss: 0.3091 - val_accuracy: 0.8879\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2199 - accuracy: 0.9206 - val_loss: 0.3018 - val_accuracy: 0.8903\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2109 - accuracy: 0.9236 - val_loss: 0.2984 - val_accuracy: 0.8927\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2009 - accuracy: 0.9284 - val_loss: 0.3011 - val_accuracy: 0.8938\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1931 - accuracy: 0.9309 - val_loss: 0.2976 - val_accuracy: 0.8969\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1859 - accuracy: 0.9340 - val_loss: 0.3060 - val_accuracy: 0.8922\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1792 - accuracy: 0.9353 - val_loss: 0.3031 - val_accuracy: 0.8961\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1718 - accuracy: 0.9380 - val_loss: 0.3175 - val_accuracy: 0.8938\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1672 - accuracy: 0.9399 - val_loss: 0.3056 - val_accuracy: 0.8984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLsS1GZ9zY_g",
        "outputId": "6ec08739-c6ca-4872-99a6-8e64418f25e1"
      },
      "source": [
        "export_path = gen_export_path(2)\n",
        "tf.saved_model.save(model2, export_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
            "INFO:tensorflow:Assets written to: /tmp/2/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBUegFiEsNRv",
        "outputId": "d44c6c15-538a-49f2-a2b6-bda5d5d34192"
      },
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['input_2'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 28, 28, 1)\n",
            "        name: serving_default_input_2:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_2'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 10)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0629 17:27:51.879715 139632864188288 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'input_2')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jfa7NfNtzyB"
      },
      "source": [
        "# Prepare TF Server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX3f9Ue-tRGC"
      },
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q-zCoACt51C",
        "outputId": "2e3b5b8d-b2eb-4a37-b09c-6b5db2dfff18"
      },
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=fashion_model \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting job # 0 in a separate thread.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3y8-szRuBxJ",
        "outputId": "6c4a2dd4-2492-4647-fd36-fe788a639c58"
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-29 17:15:41.249794: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /tmp/1\n",
            "2021-06-29 17:15:41.257079: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 70159 microseconds.\n",
            "2021-06-29 17:15:41.258038: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /tmp/1/assets.extra/tf_serving_warmup_requests\n",
            "2021-06-29 17:15:41.258159: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: fashion_model version: 1}\n",
            "2021-06-29 17:15:41.258721: I tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models\n",
            "2021-06-29 17:15:41.258780: I tensorflow_serving/model_servers/server.cc:367] Profiler service is enabled\n",
            "2021-06-29 17:15:41.259166: I tensorflow_serving/model_servers/server.cc:393] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "2021-06-29 17:15:41.259645: I tensorflow_serving/model_servers/server.cc:414] Exporting HTTP/REST API at:localhost:8501 ...\n",
            "[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GgSa_q4xsOM"
      },
      "source": [
        "# Test TF Server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV2lOFid0VAl"
      },
      "source": [
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": X_test[0:3].tolist()})\n",
        "headers = {\"content-type\": \"application/json\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbBAYMJRuM-J",
        "outputId": "a04f055e-2cfc-4b70-9cbd-65957b284afc"
      },
      "source": [
        "# Model - Large\n",
        "r = requests.post('http://localhost:8501/v1/models/fashion_model/versions/1:predict', data=data, headers=headers)     # specifically ver1\n",
        "p = r.json()['predictions']\n",
        "p = np.array(p).argmax(axis=1)\n",
        "p = [labels[p_] for p_ in p]\n",
        "a = [labels[i] for i in y_test[:3]]\n",
        "print(p, a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ankle boot', 'Pullover', 'Trouser'] ['Ankle boot', 'Pullover', 'Trouser']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJqM9RVkykgS",
        "outputId": "5d199965-3a52-4f05-a62d-f6826b596d10"
      },
      "source": [
        "# Model - Tiny\n",
        "# r = requests.post('http://localhost:8501/v1/models/fashion_model:predict', data=data, headers=headers)  # latest version\n",
        "r = requests.post('http://localhost:8501/v1/models/fashion_model/versions/2:predict', data=data, headers=headers)     # specifically ver2\n",
        "p = r.json()['predictions']\n",
        "p = np.array(p).argmax(axis=1)\n",
        "p = [labels[p_] for p_ in p]\n",
        "a = [labels[i] for i in y_test[:3]]\n",
        "print(p, a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ankle boot', 'Pullover', 'Trouser'] ['Ankle boot', 'Pullover', 'Trouser']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKnRZMW50TNa",
        "outputId": "5e86a94b-cb57-41e2-e1bd-90fdb501dbf6"
      },
      "source": [
        "# non-existent model will return Response 404\n",
        "requests.post('http://localhost:8501/v1/models/fashion_model/versions/3:predict', data=data, headers=headers)     # specifically ver2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [404]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}