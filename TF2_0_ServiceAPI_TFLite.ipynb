{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2.0_ServiceAPI_TFLite",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP9BIM9t64ZbAYKjQL9BEo+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmVu4hzMkBPi"
      },
      "source": [
        "# Import Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FXWnDi0tV8l",
        "outputId": "dcbbfe95-2b95-44ac-8f5d-7e1bfd4670fc"
      },
      "source": [
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update\n",
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2943  100  2943    0     0   136k      0 --:--:-- --:--:-- --:--:--  136k\n",
            "OK\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:8 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [340 B]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Get:10 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [347 B]\n",
            "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,418 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:17 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,221 kB]\n",
            "Hit:19 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [637 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,780 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,188 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,658 kB]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [910 kB]\n",
            "Get:26 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.8 kB]\n",
            "Fetched 12.1 MB in 3s (3,915 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "58 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 58 not upgraded.\n",
            "Need to get 326 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.5.1 [326 MB]\n",
            "Fetched 326 MB in 4s (78.4 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 160815 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.5.1_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.5.1) ...\n",
            "Setting up tensorflow-model-server (2.5.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGj3Fhr7j47R"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "import requests\n",
        "import subprocess\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCcG0a1UvssH"
      },
      "source": [
        "MODEL_DIR = tempfile.gettempdir()\n",
        "def gen_export_path(ver):    \n",
        "    export_path = os.path.join(MODEL_DIR, str(ver))\n",
        "    return export_path "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XSp0TmsyMzO"
      },
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR\n",
        "# !ps -ef\n",
        "# !kill <PID>\n",
        "# !!killall5 -9"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPnxvzbWz5yZ",
        "outputId": "6afe60d2-fe6b-4c15-c13d-abc64ad7c664"
      },
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=fashion_model \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting job # 0 in a separate thread.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spTa54MTkLSW"
      },
      "source": [
        "# Build Model & Serve API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eYEKjqykCZm",
        "outputId": "30da0875-224f-4440-b5d4-590f66de0bfd"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "X_train, X_test = np.expand_dims(X_train, -1), np.expand_dims(X_test, -1) # expand (height x weight) to (height x weight x color), color = 1 for grayscale\n",
        "print(X_train.shape, X_test.shape)\n",
        "\n",
        "K = len(set(y_train))\n",
        "print(K)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28, 1) (10000, 28, 28, 1)\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzAqMqgFxapV"
      },
      "source": [
        "# Label mapping\n",
        "labels = '''T-shirt/top\n",
        "Trouser\n",
        "Pullover\n",
        "Dress\n",
        "Coat\n",
        "Sandal\n",
        "Shirt\n",
        "Sneaker\n",
        "Bag\n",
        "Ankle boot'''.split(\"\\n\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j7D8Brfy5F8",
        "outputId": "01c6d8b6-0ad7-4ffb-f1bf-e28ffd187f54"
      },
      "source": [
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update\n",
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2943  100  2943    0     0   169k      0 --:--:-- --:--:-- --:--:--  169k\n",
            "OK\n",
            "Hit:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "58 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tensorflow-model-server is already the newest version (2.5.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 58 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqPOdOBA5up0"
      },
      "source": [
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": X_test[0:3].tolist()})\n",
        "headers = {\"content-type\": \"application/json\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKAMof-Vs86S"
      },
      "source": [
        "## Model - Large"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfzVphIWkcxt",
        "outputId": "a3a0d161-9103-4c1b-9c07-34a7ce980347"
      },
      "source": [
        "i = Input(shape=X_train[0].shape)\n",
        "x = Conv2D(32, (3, 3), strides=2, activation='relu')(i)\n",
        "x = Conv2D(64, (3, 3), strides=2, activation='relu')(x)\n",
        "x = Conv2D(128, (3, 3), strides=2, activation='relu')(x)\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(K, activation='softmax')(x)\n",
        "\n",
        "model = Model(i, x)\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 13, 13, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 6, 6, 64)          18496     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 2, 2, 128)         73856     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 360,458\n",
            "Trainable params: 360,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6Qr4JM2lSPe",
        "outputId": "9eff974a-7977-4d49-cdb7-e4fbccf822a3"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 38s 3ms/step - loss: 0.5201 - accuracy: 0.8074 - val_loss: 0.4095 - val_accuracy: 0.8444\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3602 - accuracy: 0.8654 - val_loss: 0.3437 - val_accuracy: 0.8707\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3117 - accuracy: 0.8837 - val_loss: 0.3265 - val_accuracy: 0.8781\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2790 - accuracy: 0.8953 - val_loss: 0.3136 - val_accuracy: 0.8846\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2535 - accuracy: 0.9049 - val_loss: 0.2865 - val_accuracy: 0.8980\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2335 - accuracy: 0.9109 - val_loss: 0.2847 - val_accuracy: 0.8956\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2140 - accuracy: 0.9184 - val_loss: 0.2886 - val_accuracy: 0.8972\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1976 - accuracy: 0.9241 - val_loss: 0.3078 - val_accuracy: 0.8966\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1840 - accuracy: 0.9303 - val_loss: 0.3028 - val_accuracy: 0.8986\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1735 - accuracy: 0.9338 - val_loss: 0.3028 - val_accuracy: 0.9011\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1599 - accuracy: 0.9391 - val_loss: 0.3157 - val_accuracy: 0.8986\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1523 - accuracy: 0.9421 - val_loss: 0.3223 - val_accuracy: 0.8997\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1416 - accuracy: 0.9460 - val_loss: 0.3334 - val_accuracy: 0.9007\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1359 - accuracy: 0.9473 - val_loss: 0.3349 - val_accuracy: 0.9035\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1265 - accuracy: 0.9512 - val_loss: 0.3581 - val_accuracy: 0.8981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n1zZveGltiG",
        "outputId": "efa4b9b7-5ffd-493d-f38b-9121645e90eb"
      },
      "source": [
        "export_path = gen_export_path(1)\n",
        "tf.saved_model.save(model, export_path)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
            "INFO:tensorflow:Assets written to: /tmp/1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4MlIEycwsjF",
        "outputId": "374d4195-a741-450d-bbd6-ea123b378111"
      },
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['input_1'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 28, 28, 1)\n",
            "        name: serving_default_input_1:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_1'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 10)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0708 16:12:28.099042 140719718954880 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_1: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'input_1')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_1: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'input_1')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_1: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'input_1')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_1: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'input_1')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_1: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'input_1')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbBAYMJRuM-J",
        "outputId": "d0c4cfac-5917-4e90-e2f9-632d50af8681"
      },
      "source": [
        "# Model - Large\n",
        "r = requests.post('http://localhost:8501/v1/models/fashion_model/versions/1:predict', data=data, headers=headers)     # specifically ver1\n",
        "p = r.json()['predictions']\n",
        "p = np.array(p).argmax(axis=1)\n",
        "p = [labels[p_] for p_ in p]\n",
        "a = [labels[i] for i in y_test[:3]]\n",
        "print(p, a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ankle boot', 'Pullover', 'Trouser'] ['Ankle boot', 'Pullover', 'Trouser']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjHDjCujzMyl"
      },
      "source": [
        "## Model - Tiny"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBr5eMkvzOgz",
        "outputId": "caca059a-cda2-43fa-bd99-c78b883e0fdf"
      },
      "source": [
        "i = Input(shape=X_train[0].shape)\n",
        "x = Conv2D(32, (3, 3), strides=2, activation='relu')(i)\n",
        "x = Flatten()(x)\n",
        "x = Dense(K, activation='softmax')(x)\n",
        "\n",
        "model2 = Model(i, x)\n",
        "model2.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 32)        320       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                54090     \n",
            "=================================================================\n",
            "Total params: 54,410\n",
            "Trainable params: 54,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atI3yPEkzQuW",
        "outputId": "7f6b122f-f792-44ab-c2a9-245eb2dd9530"
      },
      "source": [
        "model2.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "r2 = model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4793 - accuracy: 0.8326 - val_loss: 0.4057 - val_accuracy: 0.8543\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3414 - accuracy: 0.8793 - val_loss: 0.3462 - val_accuracy: 0.8786\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3015 - accuracy: 0.8928 - val_loss: 0.3376 - val_accuracy: 0.8793\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2778 - accuracy: 0.9008 - val_loss: 0.3151 - val_accuracy: 0.8868\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2609 - accuracy: 0.9064 - val_loss: 0.3086 - val_accuracy: 0.8899\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2464 - accuracy: 0.9105 - val_loss: 0.3116 - val_accuracy: 0.8889\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2350 - accuracy: 0.9154 - val_loss: 0.3053 - val_accuracy: 0.8917\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2232 - accuracy: 0.9192 - val_loss: 0.3043 - val_accuracy: 0.8934\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2129 - accuracy: 0.9237 - val_loss: 0.3067 - val_accuracy: 0.8925\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2028 - accuracy: 0.9273 - val_loss: 0.3034 - val_accuracy: 0.8955\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1937 - accuracy: 0.9306 - val_loss: 0.3113 - val_accuracy: 0.8943\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1861 - accuracy: 0.9342 - val_loss: 0.3116 - val_accuracy: 0.8930\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1792 - accuracy: 0.9365 - val_loss: 0.3090 - val_accuracy: 0.8954\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1730 - accuracy: 0.9380 - val_loss: 0.3073 - val_accuracy: 0.8970\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1662 - accuracy: 0.9413 - val_loss: 0.3098 - val_accuracy: 0.8964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLsS1GZ9zY_g",
        "outputId": "46bc4c6e-064d-4596-ad1d-81dea97c39ae"
      },
      "source": [
        "export_path = gen_export_path(2)\n",
        "tf.saved_model.save(model2, export_path)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
            "INFO:tensorflow:Assets written to: /tmp/2/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBUegFiEsNRv",
        "outputId": "68867374-f783-4ca7-a251-54a287b640aa"
      },
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['input_2'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 28, 28, 1)\n",
            "        name: serving_default_input_2:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_2'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 10)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0708 16:13:05.994067 140186128680832 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'input_2')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJqM9RVkykgS",
        "outputId": "3cf79b15-a747-4c62-d32d-202cf40bbf2b"
      },
      "source": [
        "# Model - Tiny\n",
        "# r = requests.post('http://localhost:8501/v1/models/fashion_model:predict', data=data, headers=headers)  # latest version\n",
        "r = requests.post('http://localhost:8501/v1/models/fashion_model/versions/2:predict', data=data, headers=headers)     # specifically ver2\n",
        "p = r.json()['predictions']\n",
        "p = np.array(p).argmax(axis=1)\n",
        "p = [labels[p_] for p_ in p]\n",
        "a = [labels[i] for i in y_test[:3]]\n",
        "print(p, a)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ankle boot', 'Pullover', 'Trouser'] ['Ankle boot', 'Pullover', 'Trouser']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKnRZMW50TNa",
        "outputId": "0005caf9-34ad-414e-f117-dd5bfa3483dd"
      },
      "source": [
        "# non-existent model will return Response 404\n",
        "requests.post('http://localhost:8501/v1/models/fashion_model/versions/3:predict', data=data, headers=headers)     # specifically ver2"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [404]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYtTy8L9u4Az"
      },
      "source": [
        "# Conversion to TF Lite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3-hrqJ-8VA0"
      },
      "source": [
        "!rm -rf models\n",
        "!mkdir models"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGJCxWml7ZIO",
        "outputId": "3c4bcace-2412-49df-9aea-eb109dd9b88a"
      },
      "source": [
        "model_tflite = tf.lite.TFLiteConverter.from_keras_model(model).convert()\n",
        "with open(\"models/model.tflite\", \"wb\") as f:\n",
        "    f.write(model_tflite)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp23bf8_b2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp23bf8_b2/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5ov8j5M8I8n"
      },
      "source": [
        "model.save('./models/my_model.h5')"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTLLERu78Q7A",
        "outputId": "a6b31d64-d26f-45ad-ef9d-2970854530ed"
      },
      "source": [
        "!ls -l models\n",
        "# tf lite model is much smaller"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 5692\n",
            "-rw-r--r-- 1 root root 1444956 Jul  8 16:28 model.tflite\n",
            "-rw-r--r-- 1 root root 4379368 Jul  8 16:28 my_model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "QGe8XGqVu6O7",
        "outputId": "f98c7e6f-b1f1-49be-fbe0-600804f480de"
      },
      "source": [
        "import time\n",
        "while True:\n",
        "    print('.')\n",
        "    time.sleep(60)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-fce8a224f6f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}